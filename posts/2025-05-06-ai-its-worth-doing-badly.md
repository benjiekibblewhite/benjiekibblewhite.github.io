---
layout: post
title: "Writing vs AI: It's Worth Doing Badly"
date: 2025-05-06 10:24am
categories:
  - blog
tags:
  - ai
  - writing
  - llms
link: "https://claytonwramsey.com/blog/prompt/"
author: "Benjie Kibblewhite"
---

LLMs, when to use them, and if we even should, are the hot-ticket question of the day. (Well, minus the facism) I loved [Clayton Ramsey's take](https://claytonwramsey.com/blog/prompt/) on this, namely: **If it’s worth doing, it’s worth doing badly.**

When thinking about this question myself, that's more or less where I landed as well. I had been reading a professor talking about strategies she uses around student's use of LLMs in her writing class, and I wondered how I would handle the same thing. I got stuck on trying to answer my hypothetical student's question: Why? Why not use LLMs?

When we learn a skill and practice it, we literally change our brains. We forge new connections, and strengthen them as we repeat the skill. Offloading that work to the machine might get a job done. It might check a box off a to-do list. But in exchange, we give up the opportunity to change, and grow. Writing something ourselves is worth doing poorly, because we will not always do it poorly, and, even in doing it poorly, we are reinforcing those grooves of skill and knowledge and ability in the actual, literal physical structure of our brains. Skills change not only what we're capable of, but who we are.

I use LLMs in my work, to help with mundane coding tasks. So I'm not on the side that says, "These tools are all bad, with no upside, and we should never use them." They're pretty remarkable tools at some tasks... and I'm also defensively interested in understanding them so that I can future-proof myself and still have a job in 5, 10, 15 years.

Yet, we need to be very careful about using them to _learn_ something. We should be very aware of what we give up in that exchange, and be very critical if that's something we're willing to lose.
